{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659bf9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbe9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import SystemMessage\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3642ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "당신의 역할은 사용자가 어떤 종류의 프롬프트 템플릿을 만들고 싶은지에 대한 정보를 얻는 것입니다.\n",
    "\n",
    "당신은 사용자로부터 다음 정보를 얻어야 합니다:\n",
    "\n",
    "프롬프트의 목표는 무엇인가요?\n",
    "\n",
    "프롬프트 템플릿에 어떤 변수가 들어가는가요?\n",
    "\n",
    "출력 결과가 하지 말아야 할 제약사항이 있는가요?\n",
    "\n",
    "출력 결과가 반드시 따라야 할 요구사항이 있는가요?\n",
    "\n",
    "이 정보들을 명확하게 파악할 수 없는 경우, 사용자에게 구체적으로 질문해서 확인하세요!\n",
    "무턱대고 추측해서는 안 됩니다.\n",
    "\n",
    "정보를 모두 파악한 뒤, 관련 도구를 호출하세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6527c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages_info(messages):\n",
    "    return [SystemMessage(content=template)] + messages\n",
    "\n",
    "\n",
    "class PromptInstructions(BaseModel):\n",
    "    \"\"\"Instructions on how to prompt the LLM.\"\"\"\n",
    "\n",
    "    objective: str\n",
    "    variables: List[str]\n",
    "    constraints: List[str]\n",
    "    requirements: List[str]\n",
    "\n",
    "\n",
    "llm = ChatOllama(model='qwen',temperature=0)\n",
    "llm_with_tool = llm.bind_tools([PromptInstructions])\n",
    "\n",
    "\n",
    "def info_chain(state):\n",
    "    messages = get_messages_info(state[\"messages\"])\n",
    "    response = llm_with_tool.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a990125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "# New system prompt\n",
    "prompt_system = \"\"\"Based on the following requirements, write a good prompt template:\n",
    "\n",
    "{reqs}\"\"\"\n",
    "\n",
    "\n",
    "# Function to get the messages for the prompt\n",
    "# Will only get messages AFTER the tool call\n",
    "def get_prompt_messages(messages: list):\n",
    "    tool_call = None\n",
    "    other_msgs = []\n",
    "    for m in messages:\n",
    "        if isinstance(m, AIMessage) and m.tool_calls:\n",
    "            tool_call = m.tool_calls[0][\"args\"]\n",
    "        elif isinstance(m, ToolMessage):\n",
    "            continue\n",
    "        elif tool_call is not None:\n",
    "            other_msgs.append(m)\n",
    "    return [SystemMessage(content=prompt_system.format(reqs=tool_call))] + other_msgs\n",
    "\n",
    "\n",
    "def prompt_gen_chain(state):\n",
    "    messages = get_prompt_messages(state[\"messages\"])\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a85713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import END\n",
    "\n",
    "\n",
    "def get_state(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"add_tool_message\"\n",
    "    elif not isinstance(messages[-1], HumanMessage):\n",
    "        return END\n",
    "    return \"info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24abc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"info\", info_chain)\n",
    "workflow.add_node(\"prompt\", prompt_gen_chain)\n",
    "\n",
    "\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: State):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Prompt generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\"info\", get_state, [\"add_tool_message\", \"info\", END])\n",
    "workflow.add_edge(\"add_tool_message\", \"prompt\")\n",
    "workflow.add_edge(\"prompt\", END)\n",
    "workflow.add_edge(START, \"info\")\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e00981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36831724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User (q/Q to quit): hi\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "registry.ollama.ai/library/qwen:latest does not support tools (status code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2024\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2018\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2019\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2021\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 2024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2025\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2027\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2028\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2030\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   2031\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2032\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langgraph\\utils\\runnable.py:546\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    543\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    544\u001b[0m )\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langgraph\\utils\\runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36minfo_chain\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minfo_chain\u001b[39m(state):\n\u001b[0;32m     19\u001b[0m     messages \u001b[38;5;241m=\u001b[39m get_messages_info(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_with_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5409\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5414\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5415\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5418\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:371\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    367\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    368\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 371\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    381\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:956\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    954\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    955\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:775\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    774\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 775\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m         )\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1021\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1021\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_ollama\\chat_models.py:741\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    736\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    740\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m--> 741\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m final_chunk\u001b[38;5;241m.\u001b[39mgeneration_info\n\u001b[0;32m    745\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    746\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(\n\u001b[0;32m    747\u001b[0m             content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mgeneration_info,\n\u001b[0;32m    753\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_ollama\\chat_models.py:678\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    671\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    676\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[0;32m    677\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterate_over_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_ollama\\chat_models.py:763\u001b[0m, in \u001b[0;36mChatOllama._iterate_over_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iterate_over_stream\u001b[39m(\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    758\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[0;32m    759\u001b[0m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    761\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatGenerationChunk]:\n\u001b[0;32m    762\u001b[0m     is_thinking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 763\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\langchain_ollama\\chat_models.py:665\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m chat_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_params(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_params)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_params)\n",
      "File \u001b[1;32mc:\\Users\\songs\\anaconda3\\envs\\projectH\\Lib\\site-packages\\ollama\\_client.py:168\u001b[0m, in \u001b[0;36mClient._request.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    167\u001b[0m   e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 168\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_lines():\n\u001b[0;32m    171\u001b[0m   part \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "\u001b[1;31mResponseError\u001b[0m: registry.ollama.ai/library/qwen:latest does not support tools (status code: 400)",
      "\u001b[0mDuring task with name 'info' and id '5de5f8f4-a95b-f4b8-fd13-3707a5aa2764'"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "cached_human_responses = [\"hi!\", \"rag prompt\", \"1 rag, 2 none, 3 no, 4 no\", \"red\", \"q\"]\n",
    "cached_response_index = 0\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "while True:\n",
    "    try:\n",
    "        user = input(\"User (q/Q to quit): \")\n",
    "    except:\n",
    "        user = cached_human_responses[cached_response_index]\n",
    "        cached_response_index += 1\n",
    "    print(f\"User (q/Q to quit): {user}\")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    output = None\n",
    "    for output in graph.stream(\n",
    "        {\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"\n",
    "    ):\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if output and \"prompt\" in output:\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4582b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
